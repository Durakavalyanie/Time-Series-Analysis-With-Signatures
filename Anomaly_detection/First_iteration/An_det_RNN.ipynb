{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee515f32-afd6-429f-b627-9f854b046bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import iisignature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ffec6-2437-4a7a-97be-40c017ea7f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ou_process(n_samples, n_steps, mu=0, theta=0.15, sigma=0.3):\n",
    "    dt = 1.0\n",
    "    X = np.zeros((n_samples, n_steps, 1), dtype=np.float32)\n",
    "    X[:,0,0] = mu\n",
    "    for t in range(1, n_steps):\n",
    "        dX = theta * (mu - X[:, t-1, 0]) * dt + sigma * np.random.normal(size=n_samples) * np.sqrt(dt)\n",
    "        X[:, t, 0] = X[:, t-1,0] + dX\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808147b3-b94b-425a-be9f-9cced87d4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multidim_ou_process(n_samples, n_steps, mu=0, theta=0.15, sigma=0.3, n_features=1):\n",
    "    dt = 1.0\n",
    "    X = np.zeros((n_samples, n_steps, n_features), dtype=np.float32)\n",
    "    X[:,0,:] = mu\n",
    "    for t in range(1, n_steps):\n",
    "        dX = theta * (mu - X[:, t-1, :]) * dt + sigma * np.random.normal(size=(n_samples, n_features)) * np.sqrt(dt)\n",
    "        X[:, t, :] = X[:, t-1, :] + dX\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b860870c-573d-4269-a73e-5118077e3ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddTimeline(X):\n",
    "    samples, steps, features = X.shape\n",
    "    timeline = np.linspace(0, 1, steps)  # shape: (steps,)\n",
    "    timeline = np.tile(timeline, (samples, 1))  # shape: (samples, steps)\n",
    "    timeline = timeline[:, :, np.newaxis]  # shape: (samples, steps, 1)\n",
    "\n",
    "    X_new = np.concatenate((timeline, X), axis=2)  # вставка timeline как первой фичи\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b2306-eac5-4ae0-af71-adfd54c38574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_signature(X, sig_level):\n",
    "    '''\n",
    "    X : (samples, steps, features) including time feature\n",
    "    '''\n",
    "    n_samples, n_steps, n_features = X.shape\n",
    "    sig_length = iisignature.siglength(n_features, sig_level)\n",
    "\n",
    "    Y = np.zeros((n_samples, n_steps, sig_length), dtype=np.float32)\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_steps):\n",
    "            Y[i, j] = iisignature.sig(X[i, : j+1], sig_level)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23895c9b-f254-4b3c-8676-5e58e451630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_logsignature(X, sig_level):\n",
    "    '''\n",
    "    X : (samples, steps, features) including time feature\n",
    "    '''\n",
    "    n_samples, n_steps, n_features = X.shape\n",
    "    s = iisignature.prepare(n_features, sig_level)\n",
    "    sig_length = iisignature.logsiglength(n_features, sig_level)\n",
    "\n",
    "    Y = np.zeros((n_samples, n_steps, sig_length), dtype=np.float32)\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_steps):\n",
    "            Y[i, j] = iisignature.logsig(X[i, : j+1], s)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83414c-b582-4358-bb36-dd4d822dbd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomizedSignatureBatch(X_batch, k, activation='tanh', seed=None):\n",
    "    '''\n",
    "    Compute Randomized Signature with random matrixes A, b shared between samples\n",
    "    X_batch : (samples, timesteps, features)\n",
    "    \n",
    "    activation func: 'linear', 'tanh', 'relu' or callable\n",
    "\n",
    "    seed : random seed\n",
    "\n",
    "    Returns Z_batch : (samples, steps, k)\n",
    "    k-dimensional r-sig at each time step for each sample.\n",
    "    '''\n",
    "    X_batch = np.asarray(X_batch)\n",
    "    samples, n, d = X_batch.shape\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    A = rng.standard_normal(size=(d, k, k))\n",
    "    b = rng.standard_normal(size=(d, k))\n",
    "\n",
    "    Z_batch = np.zeros((samples, n, k))\n",
    "    Z_batch[:, 0, :] = rng.standard_normal(size=(samples, k))\n",
    "\n",
    "    if activation == 'linear':\n",
    "        def sigma(x): return x / np.sqrt(k)\n",
    "    elif activation == 'tanh':\n",
    "        sigma = np.tanh\n",
    "    elif activation == 'relu':\n",
    "        sigma = lambda x: np.maximum(x, 0)\n",
    "    elif callable(activation):\n",
    "        sigma = activation\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported activation\")\n",
    "\n",
    "    dX_batch = np.diff(X_batch, axis=1)\n",
    "\n",
    "    for j in range(1, n):\n",
    "        z_prev = Z_batch[:, j-1, :]\n",
    "        increment = np.zeros_like(z_prev)\n",
    "        for i in range(d):\n",
    "            projected = (z_prev @ A[i].T) + b[i]\n",
    "            increment += sigma(projected) * dX_batch[:, j-1, i:i+1]\n",
    "        Z_batch[:, j, :] = z_prev + increment\n",
    "\n",
    "    return Z_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983333c9-e9ea-49b4-bdab-2da960e70578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold(scores, true_labels):\n",
    "    thresholds = np.unique(scores)  # > treshold => 1\n",
    "    best_accuracy = 0\n",
    "    best_f1 = 0\n",
    "    best_accuracy_threshold = 0\n",
    "    best_f1_threshold = 0\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        predicted_labels = (scores > threshold).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_accuracy_threshold = threshold\n",
    "\n",
    "        f1 = f1_score(true_labels, predicted_labels)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_f1_threshold = threshold\n",
    "\n",
    "    return best_accuracy_threshold, best_f1_threshold, best_accuracy, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb285d-f380-4a93-9be8-f6e18ba1f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNAutoencoder(nn.Module):\n",
    "    '''\n",
    "    RNN autoencoder with repeated input(last hidden state) to decoder in direct order(from 0 timestep to n-1)\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, rnn_type,\n",
    "                 rnn_layers=1, activation=nn.ReLU, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        if rnn_type == 'gru':\n",
    "            self.encoder_rnn = nn.GRU(input_dim, hidden_dim, num_layers=rnn_layers, batch_first=True)\n",
    "            self.decoder_rnn = nn.GRU(hidden_dim, input_dim, num_layers=rnn_layers, batch_first=True)\n",
    "        elif rnn_type == 'lstm':\n",
    "            self.encoder_rnn = nn.LSTM(input_dim, hidden_dim, num_layers=rnn_layers, batch_first=True)\n",
    "            self.decoder_rnn = nn.LSTM(hidden_dim, input_dim, num_layers=rnn_layers, batch_first=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported RNN type\")\n",
    "\n",
    "        self.fc_enc = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_dec = nn.Linear(latent_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, steps, _ = x.size()\n",
    "        encoded_seq, hidden = self.encoder_rnn(x)\n",
    "\n",
    "        if isinstance(hidden, tuple):  # LSTM\n",
    "            hidden = hidden[0]\n",
    "\n",
    "        hidden_last = hidden[-1]\n",
    "\n",
    "        latent = self.fc_enc(hidden_last)\n",
    "\n",
    "        decoder_input = self.fc_dec(latent).unsqueeze(1).repeat(1, steps, 1)\n",
    "        decoded_seq, _ = self.decoder_rnn(decoder_input)\n",
    "\n",
    "        return decoded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c2f08-fae5-4c71-b87b-c52c6f63badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualMetricEarlyStopping:\n",
    "    def __init__(self, patience : int, min_delta : float):\n",
    "        '''\n",
    "        patience: сколько эпох ждать перед остановкой\n",
    "        min_delta: минимальное относительное улучшение (0.01 = 1%)\n",
    "        \"'''\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.history = []\n",
    "\n",
    "    def step(self, accuracy, roc_auc):\n",
    "        self.history.append((accuracy, roc_auc))\n",
    "        \n",
    "        if len(self.history) <= self.patience:\n",
    "            return False \n",
    "\n",
    "        recent = self.history[-self.patience-1:]\n",
    "        base_acc, base_auc = recent[0]\n",
    "        improved = False\n",
    "\n",
    "        for acc, auc in recent[1:]:\n",
    "            acc_gain = (acc - base_acc) / max(base_acc, 1e-6)\n",
    "            auc_gain = (auc - base_auc) / max(base_auc, 1e-6)\n",
    "\n",
    "            if acc_gain >= self.min_delta or auc_gain >= self.min_delta:\n",
    "                improved = True\n",
    "                break\n",
    "\n",
    "        return not improved\n",
    "\n",
    "def train_RNN(X_normal, X_test, labels, model_params, train_params, device=None):\n",
    "    '''\n",
    "    Train an RNN Autoencoder on normal data with validation on X_test\n",
    "    '''\n",
    "    num_epochs = train_params[\"num_epochs\"]\n",
    "    lr = train_params[\"lr\"]\n",
    "    batch_size = train_params[\"batch_size\"]\n",
    "    weight_decay = train_params[\"weight_decay\"]\n",
    "    patience = train_params[\"patience\"]\n",
    "    min_delta = train_params[\"min_delta\"]\n",
    "\n",
    "    best_acc = 0\n",
    "    best_acc_epoch = -1\n",
    "    best_roc_auc = 0\n",
    "    best_roc_auc_epoch = -1\n",
    "    best_metrics = {}\n",
    "    \n",
    "    if (train_params[\"standard_scaler\"]) :\n",
    "        samples, timesteps, features = X_normal.shape\n",
    "        test_samples = X_test.shape[0]\n",
    "        X_normal_reshaped = X_normal.reshape(-1, features)\n",
    "        X_test_reshaped = X_test.reshape(-1, features)\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "        X_normal_scaled = scaler.fit_transform(X_normal_reshaped)\n",
    "        X_test_scaled = scaler.transform(X_test_reshaped)\n",
    "    \n",
    "        X_normal = X_normal_scaled.reshape(samples, timesteps, features)\n",
    "        X_test = X_test_scaled.reshape(test_samples, timesteps, features)\n",
    "\n",
    "    metrics = np.zeros((num_epochs, 2))\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if isinstance(X_normal, np.ndarray):\n",
    "        X_normal = torch.from_numpy(X_normal).float()\n",
    "        \n",
    "    dataset = TensorDataset(X_normal)\n",
    "    loader = DataLoader(dataset, batch_size=train_params['batch_size'], shuffle=True)\n",
    "\n",
    "    model = RNNAutoencoder(\n",
    "        input_dim=X_normal.shape[-1],\n",
    "        hidden_dim=model_params['hidden_dim'],\n",
    "        latent_dim = model_params['latent_dim'],\n",
    "        rnn_type=model_params['rnn_type'],\n",
    "        rnn_layers = model_params['rnn_layers'],\n",
    "        dropout=model_params['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=num_epochs//8, gamma=0.8)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    early_stopper = DualMetricEarlyStopping(patience, min_delta)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for (x_batch,) in loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            x_recon = model(x_batch)\n",
    "            loss = criterion(x_recon, x_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * x_batch.size(0)\n",
    "\n",
    "        epoch_loss /= len(loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss:.6f} | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "        (treshold_acc, treshold_f1, accuracy, best_f1), roc_auc = esteem_test_RNN(model, X_test, labels)\n",
    "        print(f\"Accuracy: {accuracy:.3f}, ROC-AUC: {roc_auc:.3f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if best_acc < accuracy:\n",
    "                best_acc = accuracy\n",
    "                best_acc_epoch = epoch+1\n",
    "                \n",
    "        if best_roc_auc < roc_auc:\n",
    "            best_roc_auc = roc_auc\n",
    "            best_roc_auc_epoch = epoch+1\n",
    "\n",
    "        if early_stopper.step(accuracy, roc_auc):\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    best_metrics = {\n",
    "        \"accuracy\" : best_acc,\n",
    "        \"roc_auc\" : best_roc_auc,\n",
    "        \"best_acc_epoch\" : best_acc_epoch,\n",
    "        \"best_roc_auc_epoch\" : best_roc_auc_epoch\n",
    "        }\n",
    "\n",
    "    return best_metrics\n",
    "\n",
    "def esteem_test_RNN(RNN, RNN_test, labels_test):\n",
    "    '''\n",
    "    Test RNN model on RNN_test (samples, timesteps, features)\n",
    "    Return: (best_accuracy_threshold, best_f1_threshold, best_accuracy, best_f1), roc_auc\n",
    "    '''\n",
    "\n",
    "    (samples, steps, sig_len) = RNN_test.shape\n",
    "    esteems = np.zeros((samples))\n",
    "\n",
    "    if not isinstance(RNN_test, torch.Tensor):\n",
    "        RNN_test = torch.tensor(RNN_test, dtype=torch.float32).to(device)\n",
    "\n",
    "    for i in range(samples):  \n",
    "        RNN.eval()\n",
    "        with torch.no_grad():\n",
    "            x = RNN_test[i].reshape(1, steps, sig_len)\n",
    "            reconstructed = RNN(x)\n",
    "            loss = nn.MSELoss()(reconstructed, x)\n",
    "            esteems[i] = loss.item()\n",
    "    return find_threshold(esteems, labels_test), roc_auc_score(labels_test, esteems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62fbbc-4a66-4a93-9a93-df07bd564688",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f184e-4890-4f79-ae98-1a62be747c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = 50_000\n",
    "test_samples = 2_000\n",
    "anomaly_test_samples = int(test_samples * 0.5)\n",
    "steps = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a525002-2f1e-4522-9287-a12eb6954a36",
   "metadata": {},
   "source": [
    "Одномерные процессы О-У"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37697150-cb7c-42db-b7df-450991505054",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "train = generate_ou_process(train_samples, steps, 0, 0.15, 0.3)\n",
    "test_1 = generate_ou_process(test_samples//2, steps, 0, 0.2, 0.4)\n",
    "test_2 = generate_ou_process(test_samples//2, steps, 0, 0.15, 0.3)\n",
    "test = np.concatenate([test_1, test_2], axis=0)\n",
    "test_labels = np.zeros((test_samples)).astype(int)\n",
    "test_labels[:test_samples//2] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3195162a-7943-4cbd-a7cd-f457d0708dc5",
   "metadata": {},
   "source": [
    "Десятимерные с аномалией в случайном измерении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9408f52-2b2f-4898-b374-0ff3384ab5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "features = 10\n",
    "train = generate_multidim_ou_process(train_samples, steps, 0, 0.15, 0.3, features)\n",
    "test_1 = generate_multidim_ou_process(anomaly_test_samples, steps, 0, 0.15, 0.3, features)\n",
    "for i in range(len(test_1)):\n",
    "    test_1[i, :, i%features] = generate_ou_process(1, steps, 0, 0.3, 0.6).reshape(steps)\n",
    "test_2 = generate_multidim_ou_process(test_samples - anomaly_test_samples, steps, 0, 0.15, 0.3, features)\n",
    "test = np.concatenate([test_1, test_2], axis=0)\n",
    "test_labels = np.zeros((test_samples)).astype(int)\n",
    "test_labels[:anomaly_test_samples] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d01f37-42a9-4a81-99a1-676b5a2c9b36",
   "metadata": {},
   "source": [
    "Рандомизированная полная сигнатура"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e24915-8462-4f2e-8b62-12b3d196b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sig_len = 500\n",
    "train_r_sig = AddTimeline(train)\n",
    "test_r_sig = AddTimeline(test)\n",
    "train_r_sig = RandomizedSignatureBatch(train_r_sig, r_sig_len, activation=\"tanh\")\n",
    "test_r_sig = RandomizedSignatureBatch(test_r_sig, r_sig_len, activation=\"tanh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9cdf00-a259-4750-8b7d-b569d724c632",
   "metadata": {},
   "source": [
    "Обычная полная сигнатура"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf7009-6371-47d9-aca6-789b9a7c3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iisignature.siglength(2, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cdd084-8f9d-4016-b9ee-70b499f709af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_level = 7\n",
    "train_sig = AddTimeline(train)\n",
    "test_sig = AddTimeline(test)\n",
    "train_sig = full_signature(train, sig_level)\n",
    "test_sig = full_signature(test, sig_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c1e680-039b-4759-a2d2-51f4c9740996",
   "metadata": {},
   "source": [
    "Полная лог-сигнатура"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe19c8d2-4c6e-4ca3-9766-2d1f08a45c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iisignature.logsiglength(2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e45ec39-3cc0-4895-b100-c327f0242976",
   "metadata": {},
   "outputs": [],
   "source": [
    "logsig_level = 10\n",
    "train_logsig = AddTimeline(train)\n",
    "test_logsig = AddTimeline(test)\n",
    "train_logsig = full_logsignature(train_logsig, logsig_level)\n",
    "test_logsig = full_logsignature(test_logsig, logsig_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7565e37-c859-42fb-b1b8-4319e45d05cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_params = {\n",
    "    'hidden_dim' : 508,          # 2 * features\n",
    "    'latent_dim' : 127,         # features / 2\n",
    "    'rnn_type': 'lstm',\n",
    "    'rnn_layers' : 1,\n",
    "    'dropout' : 0.2\n",
    "}\n",
    "\n",
    "RNN_train_params = {\n",
    "    'num_epochs': 100,\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay' : 1e-4,\n",
    "    \"standard_scaler\" : True,\n",
    "    \"patience\" : 25,         # количество эпох которое даёт early stopper\n",
    "    \"min_delta\" : 0.01       # минимальное увеличение метрик для early stopping\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66704513-4255-4517-95ce-922e4b995b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = train_RNN(train_sig, test_sig, test_labels, RNN_params, RNN_train_params, device)\n",
    "print(metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-2]",
   "language": "python",
   "name": "conda-env-.conda-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
